import re
import pandas as pd
from sqlalchemy import text
from multiprocessing import Pool, cpu_count
from db_config import get_db_connection

# -----------------------------------
# Fuzzy Similarity
# -----------------------------------
try:
    from rapidfuzz import fuzz
    def sim(a, b): return fuzz.token_set_ratio(a or '', b or '') / 100
except:
    import difflib
    def sim(a, b): return difflib.SequenceMatcher(None, (a or '').lower(), (b or '').lower()).ratio()

# -----------------------------------
# Helper Functions
# -----------------------------------
def extract_pin(txt):
    if not txt:
        return None
    m = re.search(r"(?<!\d)(\d{6})(?!\d)", str(txt))
    return m.group(1) if m else None

def normalize_state_name(state_name, state_to_abbr, abbr_to_state):
    if pd.isna(state_name):
        return None
    s = state_name.strip().title()
    if s in state_to_abbr:
        return s
    elif s.upper() in abbr_to_state:
        return abbr_to_state[s.upper()]
    else:
        return s

# -----------------------------------
# Validation Logic for One Record
# -----------------------------------
def validate_record(record, master_by_pin, country, state_to_abbr, abbr_to_state):
    try:
        addr = " ".join([
            str(x) for x in [record.get('address1'), record.get('address2'), record.get('address3')]
            if x and str(x).lower() != 'nan'
        ]).strip()

        pin = extract_pin(addr) or extract_pin(record.get('pincode'))
        city_in = str(record.get('city') or '').strip().title()
        state_in = normalize_state_name(str(record.get('state') or ''), state_to_abbr, abbr_to_state)

        city_conf = state_conf = 0
        country_conf = 1.0 if country.lower() == "india" else 0.5
        loc = None
        flag = "No"  # default
        confidence_level = "Low"

        # No pincode found â†’ immediate flag
        if not pin:
            flag = "Yes"
        else:
            dfp = master_by_pin.get(pin)
            if dfp is None or dfp.empty:
                # Pincode not in DB â†’ flag
                flag = "Yes"
            else:
                # Derive best match based on city
                dfp['city_sim'] = dfp['city'].apply(lambda x: sim(x, city_in))
                best = dfp.sort_values('city_sim', ascending=False).head(1).iloc[0]
                loc = best.office_name
                city_conf = best.city_sim
                state_conf = sim(best.state, state_in)

                # If multiple cities share the same pincode â†’ ambiguous
                if len(dfp['city'].unique()) > 1:
                    flag = "Yes"

                # If mismatch in state or very low similarity â†’ flag
                if city_conf < 0.4 or state_conf < 0.4:
                    flag = "Yes"

        overall = (0.5 * city_conf + 0.3 * state_conf + 0.2 * country_conf)
        if overall >= 0.85:
            confidence_level = "High"
        elif overall >= 0.6:
            confidence_level = "Medium"
        else:
            confidence_level = "Low"

        # Add additional flag logic: if both city/state missing
        if not city_in and not state_in:
            flag = "Yes"

        return {
            "Address1": addr,
            "City": best.city if 'best' in locals() else city_in,
            "State": best.state if 'best' in locals() else state_in,
            "Pincode": pin,
            "Country": country,
            "City_Confidence": round(city_conf, 3),
            "State_Confidence": round(state_conf, 3),
            "Country_Confidence": round(country_conf, 3),
            "Overall_Confidence": round(overall, 3),
            "Confidence_Level": confidence_level,
            "Flag": flag,
            "Locality": loc
        }

    except Exception as e:
        return {
            "Address1": str(record.get('address1')),
            "City": "", "State": "", "Pincode": "",
            "Country": "India",
            "City_Confidence": 0, "State_Confidence": 0, "Country_Confidence": 0,
            "Overall_Confidence": 0, "Confidence_Level": "Low",
            "Flag": f"Yes (Error: {e})", "Locality": ""
        }

# -----------------------------------
# Main Execution
# -----------------------------------
def main():
    BATCH_SIZE = 10000
    PROCESSES = min(8, cpu_count())
    eng = get_db_connection()

    # --- Load State Abbreviations ---
    abbr_path = r"C:\Users\ashish.singh\Downloads\address_validation_upload_final\datasets\abbreviation_list 1.csv"
    abbr = pd.read_csv(abbr_path)
    abbr.columns = abbr.columns.str.strip().str.lower()
    abbr['state'] = abbr['state'].str.strip().str.title()
    abbr['abbreviation'] = abbr['abbreviation'].str.strip().str.upper()
    state_to_abbr = dict(zip(abbr['state'], abbr['abbreviation']))
    abbr_to_state = dict(zip(abbr['abbreviation'], abbr['state']))
    print(f"Loaded {len(abbr)} state abbreviations.")

    # --- Load Master and Input Data ---
    with eng.begin() as con:
        master = pd.read_sql("SELECT * FROM av.master_ref", con)
        inp = pd.read_sql("SELECT * FROM av.input_address", con)

    # Normalize states
    inp['state'] = inp['state'].apply(lambda x: normalize_state_name(x, state_to_abbr, abbr_to_state))
    master['state'] = master['state'].apply(lambda x: normalize_state_name(x, state_to_abbr, abbr_to_state))

    # Group master by pincode
    master_by_pin = {p: g for p, g in master.groupby('pincode')}
    print(f"Cached {len(master_by_pin)} pincodes from master_ref.")

    # Prepare output table
    with eng.begin() as con:
        con.execute(text("""
            DROP TABLE IF EXISTS av.validation_result_final;
            CREATE TABLE av.validation_result_final(
                address1 TEXT, city TEXT, state TEXT, pincode TEXT, country TEXT,
                city_confidence NUMERIC, state_confidence NUMERIC, country_confidence NUMERIC,
                overall_confidence NUMERIC, confidence_level TEXT, flag TEXT, locality TEXT
            );
        """))

    total = len(inp)
    print(f"Starting validation of {total} addresses...")

    for b, start in enumerate(range(0, total, BATCH_SIZE), start=1):
        end = min(start + BATCH_SIZE, total)
        subset = inp.iloc[start:end]
        print(f"Processing batch {b}: rows {start + 1}-{end}...")

        with Pool(PROCESSES) as pool:
            args = [(rec, master_by_pin, "India", state_to_abbr, abbr_to_state) for rec in subset.to_dict(orient='records')]
            results = pool.starmap(validate_record, args)

        df = pd.DataFrame(results)
        file_name = f"validated_output_part{b}.xlsx"
        df.to_excel(file_name, index=False)
        print(f"âœ… Saved {file_name} ({len(df)} rows)")

        # --- Safe DB Insert ---
        df = df.fillna('').astype(str)
        df.columns = df.columns.str.lower()
        df.to_sql('validation_result_final', eng, schema='av',
                  if_exists='append', index=False, method='multi', chunksize=1000)
        print(f"âœ… Batch {b} inserted successfully ({end}/{total})\n")

    print("ðŸŽ‰ Validation completed for all batches!")

# -----------------------------------
if __name__ == "__main__":
    main()
