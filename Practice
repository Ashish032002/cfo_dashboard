import re, pandas as pd, math
from sqlalchemy import text
from multiprocessing import Pool, cpu_count
from db_config import get_db_connection

# -----------------------------
# Fuzzy similarity
# -----------------------------
try:
    from rapidfuzz import fuzz
    def sim(a,b): return fuzz.token_set_ratio(a or '', b or '')/100
except:
    import difflib
    def sim(a,b): return difflib.SequenceMatcher(None,(a or '').lower(),(b or '').lower()).ratio()

# -----------------------------
# Helpers
# -----------------------------
def extract_pin(txt):
    if not txt: return None
    m=re.search(r"(?<!\\d)(\\d{6})(?!\\d)", str(txt))
    return m.group(1) if m else None

def normalize_state_name(state_name, state_to_abbr, abbr_to_state):
    if pd.isna(state_name): return None
    s = state_name.strip().title()
    if s in state_to_abbr:
        return s
    elif s.upper() in abbr_to_state:
        return abbr_to_state[s.upper()]
    else:
        return s

# -----------------------------
# Worker: validate one address
# -----------------------------
def validate_record(record, master_by_pin, country, state_to_abbr, abbr_to_state):
    try:
        addr=" ".join([str(x) for x in [record.get('address1'),record.get('address2'),record.get('address3')] if x and str(x).lower()!='nan']).strip()
        pin=extract_pin(addr) or extract_pin(record.get('pincode'))
        city_in=str(record.get('city') or '').strip().title()
        state_in=normalize_state_name(str(record.get('state') or ''),state_to_abbr,abbr_to_state)
        loc=None
        city_conf=state_conf=country_conf=0
        dfp=master_by_pin.get(pin)
        if dfp is not None and not dfp.empty:
            dfp['cs']=dfp['city'].apply(lambda x: sim(x,city_in))
            best=dfp.sort_values('cs',ascending=False).head(1).iloc[0]
            loc=best.office_name
            city_conf=best.cs
            state_conf=sim(best.state,state_in)
        else:
            best=None
        country_conf=1.0 if country.lower()=="india" else 0.5
        overall=(0.5*city_conf+0.3*state_conf+0.2*country_conf)
        flag="High" if overall>=0.85 else ("Medium" if overall>=0.6 else "Low")
        return {
            "Address1":addr,
            "City":best.city if best is not None else city_in,
            "State":best.state if best is not None else state_in,
            "Pincode":pin,
            "Country":country,
            "City_Confidence":round(city_conf,3),
            "State_Confidence":round(state_conf,3),
            "Country_Confidence":round(country_conf,3),
            "Overall_Confidence":round(overall,3),
            "Flag":flag,
            "Locality":loc
        }
    except Exception as e:
        return {"Address1": str(record.get('address1')), "Flag": f"Error: {e}"}

# -----------------------------
# Main
# -----------------------------
def main():
    BATCH_SIZE=10000
    PROCESSES=min(8, cpu_count())   # Use 8 cores max

    eng=get_db_connection()

    # Load abbreviation list
    abbr_path=r"C:\Users\ashish.singh\Downloads\address_validation_upload_final\datasets\abbreviation_list 1.csv"
    abbr=pd.read_csv(abbr_path)
    abbr.columns=abbr.columns.str.strip().str.lower()
    abbr['state']=abbr['state'].str.strip().str.title()
    abbr['abbreviation']=abbr['abbreviation'].str.strip().str.upper()
    state_to_abbr=dict(zip(abbr['state'],abbr['abbreviation']))
    abbr_to_state=dict(zip(abbr['abbreviation'],abbr['state']))

    print(f"Loaded {len(abbr)} state abbreviations.")

    # Load master + input
    with eng.begin() as con:
        master=pd.read_sql("SELECT * FROM av.master_ref", con)
        inp=pd.read_sql("SELECT * FROM av.input_address", con)

    # Normalize states
    inp['state']=inp['state'].apply(lambda x: normalize_state_name(x,state_to_abbr,abbr_to_state))
    master['state']=master['state'].apply(lambda x: normalize_state_name(x,state_to_abbr,abbr_to_state))

    # Cache master by pincode
    master_by_pin={p:g for p,g in master.groupby('pincode')}
    print(f"Cached {len(master_by_pin)} unique pincodes from master.")

    # Prepare output table
    with eng.begin() as con:
        con.execute(text("""
            DROP TABLE IF EXISTS av.validation_result_final;
            CREATE TABLE av.validation_result_final(
                address1 TEXT, city TEXT, state TEXT, pincode TEXT, country TEXT,
                city_confidence NUMERIC, state_confidence NUMERIC, country_confidence NUMERIC,
                overall_confidence NUMERIC, flag TEXT, locality TEXT);
        """))

    total=len(inp)
    print(f"Starting validation on {total} records using {PROCESSES} cores in batches of {BATCH_SIZE}...")

    # Iterate over batches
    for b,start in enumerate(range(0,total,BATCH_SIZE),start=1):
        end=min(start+BATCH_SIZE,total)
        subset=inp.iloc[start:end]
        print(f"Processing batch {b}: rows {start+1}-{end}...")

        # Parallel validation
        with Pool(PROCESSES) as pool:
            args=[(rec, master_by_pin, "India", state_to_abbr, abbr_to_state) for rec in subset.to_dict(orient='records')]
            results=pool.starmap(validate_record, args)

        df=pd.DataFrame(results)

        # Save partial Excel
        excel_name=f"validated_output_part{b}.xlsx"
        df.to_excel(excel_name,index=False)
        print(f"âœ… Saved {excel_name} ({len(df)} rows)")

        # Bulk insert into DB
        df.to_sql('validation_result_final', eng, schema='av', if_exists='append', index=False, method='multi', chunksize=1000)
        print(f"âœ… Batch {b} inserted to DB ({end}/{total})\n")

    print(f"ðŸŽ‰ Validation complete! All {total} rows processed.")

# -----------------------------
if __name__=="__main__":
    main()
